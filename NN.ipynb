{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer ,CountVectorizer\n",
    "from sklearn.model_selection import KFold,RepeatedKFold\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from collections import defaultdict,Counter\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "from textblob import TextBlob\n",
    "import xgboost as xgb\n",
    "from multiprocessing import Pool\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.sparse import  hstack\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem  import PorterStemmer\n",
    "\n",
    "\n",
    "\n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei']\n",
    "mpl.rcParams['font.family']='sans-serif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "resource = pd.read_csv('data/resources.csv')\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1541272 entries, 0 to 1541271\n",
      "Data columns (total 4 columns):\n",
      "id             1541272 non-null object\n",
      "description    1540980 non-null object\n",
      "quantity       1541272 non-null int64\n",
      "price          1541272 non-null float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 47.0+ MB\n"
     ]
    }
   ],
   "source": [
    "resource.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = resource.groupby(['id'],as_index = False).agg({'description':lambda x:''.join(x.values.astype(str))}).rename(\n",
    "    columns = {'description':'resource_description'})\n",
    "train_data = pd.merge(train_data,new_features,how='left',on='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = red> 查看缺失数据 可以看出 project_essay_4 project_essay_3 缺失率很高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = train_resource.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = (train_resource.isnull().sum() / train_resource.isnull().count()*100).sort_values(ascending =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_train_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_test = test_resource.isnull().sum().sort_values(ascending = False)\n",
    "percent_test = (test_resource.isnull().sum() / test_resource.isnull().count()*100).sort_values(ascending =False)\n",
    "missing_test_data  = pd.concat([total_test, percent_test], axis=1, keys=['Total_test', 'Percent_test'])\n",
    "missing_test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color =red>数据可视化 更好的分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,5))\n",
    "plt.title('project_is_approved count',size = 15)\n",
    "plt.xlabel('category',size = 15)\n",
    "plt.ylabel('counts',size = 15)\n",
    "\n",
    "sns.countplot('project_is_approved',data=train_resource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = red> 可以看出来自CA 有大约14％的项目 位居第一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_state_counts = train_resource.school_state.value_counts().sort_values(ascending = False)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(18,5))\n",
    "plt.title('school state counts',size = 15)\n",
    "plt.xlabel('school state',size = 15)\n",
    "plt.ylabel('counts',size = 15)\n",
    "school_state_counts.plot(kind = 'bar',fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可以看出project_grade_category一共有四类\n",
    "<font color = red>PreK-2, 3-5, 6-8, and 9-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_grade_category = train_resource.project_grade_category.value_counts().sort_values(ascending = False)\n",
    "project_grade_category = project_grade_category/train_resource.school_state.count()\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.title('project_grade_category',size = 15)\n",
    "plt.xlabel('project_grade_category',size = 15)\n",
    "plt.ylabel('counts',size = 15)\n",
    "project_grade_category.plot(kind = 'bar',fontsize=10,rot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = red> project_subject_categories最多的为 Literacy & Language  其次为 Math & Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_subject_categories = train_resource.project_subject_categories.value_counts().sort_values(ascending = False)\n",
    "project_subject_categories = project_subject_categories/train_resource.school_state.count()\n",
    "\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "plt.title('project_subject_categories',size = 15)\n",
    "plt.xlabel('project_subject_categories',size = 15)\n",
    "plt.ylabel('counts',size = 15)\n",
    "project_subject_categories.plot(kind = 'bar',fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color =red> project title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_title = train_resource.project_title.value_counts().sort_values(ascending = False).head(10)\n",
    "project_title = project_title/train_resource.project_title.count()\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "plt.title('project_title',size = 15)\n",
    "plt.xlabel('project_title',size = 15)\n",
    "plt.ylabel('counts',size = 15)\n",
    "project_title.plot(kind = 'bar',fontsize=15,rot = -45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* id                                              1081830 non-* * null object\n",
    "* teacher_id                                      1081830 non-null object\n",
    "* teacher_prefix                                  1081819 non-null object\n",
    "* school_state                                    1081830 non-null object\n",
    "* project_submitted_datetime                      1081830 non-null object\n",
    "* project_grade_category                          1081830 non-null object\n",
    "* project_subject_categories                      1081830 non-null object\n",
    "* project_subject_subcategories                   1081830 non-null object\n",
    "* project_title                                   1081830 non-null object\n",
    "* project_essay_1                                 1081830 non-null object\n",
    "* project_essay_2                                 1081830 non-null object\n",
    "* project_essay_3                                 38157 non-null object\n",
    "* project_essay_4                                 38157 non-null object\n",
    "* project_resource_summary                        1081830 non-null object\n",
    "* teacher_number_of_previously_posted_projects    1081830 non-null int64\n",
    "* project_is_approved                             1081830 non-null int64\n",
    "* description                                     1081638 non-null object\n",
    "* quantity                                        1081830 non-null int64\n",
    "* price                                           1081830 non-null float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g= sns.FacetGrid(train_resource,size=5,aspect=2)\n",
    "g.set_xlabels(label = 'num')\n",
    "plt.title(u'教师之前提交的project',size = 15)\n",
    "# plt.ylabel(u'比例')\n",
    "# plt.xlabel(u'数量')\n",
    "g.map(sns.distplot,'teacher_number_of_previously_posted_projects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data = train_resource ,col = 'teacher_prefix',size = 3 ,aspect= 1)\n",
    "g.map(sns.countplot,'project_is_approved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出 prefix和通过率并没有很大关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved_sort_byprefix = train_resource[['teacher_prefix','project_is_approved']].groupby(['teacher_prefix'],as_index= False).mean()\n",
    "sns.barplot(x='teacher_prefix',y='project_is_approved',data =approved_sort_byprefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dr prefix 的接受率 好像和 price有一定关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,15))\n",
    "\n",
    "sns.violinplot(x='teacher_prefix',y='price',hue='project_is_approved',data = train_resource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好像 并没有什么区别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved_sort_bygrade = train_resource[['project_grade_category','project_is_approved']].groupby(['project_grade_category'],as_index= False).mean()\n",
    "sns.barplot(x='project_grade_category',y='project_is_approved',data =approved_sort_bygrade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "school_state 可以作为特征之一 one-hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved_sort_bystate = train_resource[['school_state','project_is_approved']].groupby(['school_state'],as_index= False).mean().sort_values(by='project_is_approved',ascending =False)\n",
    "fig= plt.figure(figsize=(18,10))\n",
    "plt.title(u'school_state 的接受率')\n",
    "plt.xticks(size =15)\n",
    "sns.barplot(x='school_state',y='project_is_approved',data =approved_sort_bystate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "project_subject_categories 也要作为特征之一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved_sort_byscategories = train_resource[['project_subject_categories','project_is_approved']].groupby(['project_subject_categories'],as_index= False).mean().sort_values(by='project_is_approved',ascending =False)\n",
    "fig= plt.figure(figsize=(18,10))\n",
    "plt.title(u'project_subject_categories 的接受率')\n",
    "plt.xticks(size =15,rotation = -45)\n",
    "sns.barplot(x='project_subject_categories',y='project_is_approved',data =approved_sort_byscategories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved_sort_by_subcategories = train_resource[['project_subject_subcategories','project_is_approved']].groupby(['project_subject_subcategories'],as_index= False).mean().sort_values(by='project_is_approved',ascending =False)\n",
    "fig= plt.figure(figsize=(18,10))\n",
    "plt.title(u'project_subject_subcategories 的接受率')\n",
    "plt.xticks(size =15,rotation = -45)\n",
    "sns.barplot(x='project_subject_subcategories',y='project_is_approved',data =approved_sort_by_subcategories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved_sort_by_project_title = train_resource[['project_title','project_is_approved']].groupby(['project_title'],as_index= False).mean().sort_values(by='project_is_approved',ascending =False).head(50)\n",
    "fig= plt.figure(figsize=(18,10))\n",
    "plt.title(u'project_title 的接受率')\n",
    "plt.xticks(size =15,rotation = -45)\n",
    "sns.barplot(x='project_title',y='project_is_approved',data =approved_sort_by_project_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下面看看缺失值的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_resource['essay4_isnull'] = 0\n",
    "train_resource.loc[train_resource.project_essay_4.notnull(),'essay4_isnull']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_resource['essay3_isnull'] = 0\n",
    "train_resource.loc[train_resource.project_essay_3.notnull(),'essay3_isnull']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved_sort_by_essay3 = train_resource[['essay3_isnull','project_is_approved']].groupby(['essay3_isnull'],as_index= False).mean().sort_values(by='project_is_approved',ascending =False)\n",
    "plt.title(u'essay3_缺失情况 和 aprroved关系')\n",
    "sns.barplot(x='essay3_isnull',y='project_is_approved',data =approved_sort_by_essay3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved_sort_by_essay4 = train_resource[['essay4_isnull','project_is_approved']].groupby(['essay4_isnull'],as_index= False).mean().sort_values(by='project_is_approved',ascending =False)\n",
    "plt.title(u'essay4_缺失情况 和 aprroved关系')\n",
    "sns.barplot(x='essay4_isnull',y='project_is_approved',data =approved_sort_by_essay4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下面进行特征工程 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color = red> 首先进行缺失值的处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* project_essay_4\t\n",
    "* project_essay_3\t\n",
    "* description\t\n",
    "* teacher_prefix\t\n",
    "\n",
    "以上几个项存在缺失\n",
    "首先合并test和train数据,将resource文件中特征加入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['is_train_data'] = 1\n",
    "test_data['is_train_data'] = 0\n",
    "train_X = train_data.drop('project_is_approved',axis=1,inplace=False)\n",
    "test_X = test_data\n",
    "combine_data = pd.concat([train_X,test_X],axis=0,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从 resource文件中产生更多特征\n",
    "resource['total_price'] = resource['quantity'] * resource['price']\n",
    "#产生 total_price特征\n",
    "new_features = resource.groupby(['id'],as_index=False)[['total_price']].sum()\n",
    "combine_data = pd.merge(combine_data,new_features,how='left',on='id')\n",
    "\n",
    "new_features = resource.groupby(['id'],as_index=False)[['total_price']].mean()\n",
    "new_features = new_features.rename(columns={'total_price':'mean_price'})\n",
    "combine_data = pd.merge(combine_data,new_features,how='left',on='id')\n",
    "\n",
    "new_features = resource.groupby(['id'],as_index=False)[['quantity']].count()\n",
    "new_features = new_features.rename(columns={'quantity':'quantity_count'})\n",
    "combine_data = pd.merge(combine_data,new_features,how='left',on='id')\n",
    "\n",
    "new_features = resource.groupby(['id'],as_index=False)[['quantity']].sum()\n",
    "new_features = new_features.rename(columns={'quantity':'quantity_sum'})\n",
    "combine_data = pd.merge(combine_data,new_features,how='left',on='id')\n",
    "\n",
    "new_features = resource.groupby(['id'],as_index = False).agg({'description':lambda x:''.join(x.values.astype(str))}).rename(\n",
    "    columns = {'description':'resource_description'})\n",
    "combine_data = pd.merge(combine_data,new_features,how='left',on='id')\n",
    "\n",
    "#new_features['quantity_count'] = resource.groupby(['id'],as_index=False)[['quantity']].count()\n",
    "#new_features['quantity_sum'] = resource.groupby(['id'],as_index=False)[['quantity']].sum()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color =red>至上一步我们已经把 resource中的特征提取完毕,接下来处理缺失值\n",
    "    essay先不处理 之后需要用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 260115 entries, 0 to 260114\n",
      "Data columns (total 21 columns):\n",
      "id                                              260115 non-null object\n",
      "teacher_id                                      260115 non-null object\n",
      "teacher_prefix                                  260110 non-null object\n",
      "school_state                                    260115 non-null object\n",
      "project_submitted_datetime                      260115 non-null object\n",
      "project_grade_category                          260115 non-null object\n",
      "project_subject_categories                      260115 non-null object\n",
      "project_subject_subcategories                   260115 non-null object\n",
      "project_title                                   260115 non-null object\n",
      "project_essay_1                                 260115 non-null object\n",
      "project_essay_2                                 260115 non-null object\n",
      "project_essay_3                                 9078 non-null object\n",
      "project_essay_4                                 9078 non-null object\n",
      "project_resource_summary                        260115 non-null object\n",
      "teacher_number_of_previously_posted_projects    260115 non-null int64\n",
      "is_train_data                                   260115 non-null int64\n",
      "total_price                                     260115 non-null float64\n",
      "mean_price                                      260115 non-null float64\n",
      "quantity_count                                  260115 non-null int64\n",
      "quantity_sum                                    260115 non-null int64\n",
      "resource_description                            260115 non-null object\n",
      "dtypes: float64(2), int64(4), object(15)\n",
      "memory usage: 43.7+ MB\n"
     ]
    }
   ],
   "source": [
    "combine_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_data['teacher_prefix']=combine_data['teacher_prefix'].fillna(combine_data['teacher_prefix'].mode()[0])\n",
    "# combine_data.loc[combine_data.project_essay_3.isnull(),'project_essay_3'] = 'No_essay3'\n",
    "# combine_data.loc[combine_data.project_essay_4.isnull(),'project_essay_4'] = 'No_essay4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color =red>至此完成了所有的缺失值填充，接下来考虑产出一些新特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1、通过prefix可以产出性别特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gender(data):\n",
    "    if data == 'Mr.':\n",
    "        return 'male'\n",
    "    elif  data=='Mrs.' or data=='Ms.':\n",
    "        return 'female'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "combine_data ['gender'] = combine_data['teacher_prefix'].apply(add_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2、school state 取分析接受率的前5名进行标记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#找出前5名索引,和后5名索引\n",
    "school_state_sort_index = train_data[['project_is_approved','school_state']].groupby(['school_state']).mean().sort_values(by='project_is_approved',ascending =False).head(5).index\n",
    "school_state_tail_index = train_data[['project_is_approved','school_state']].groupby(['school_state']).mean().sort_values(by='project_is_approved',ascending =False).tail(5).index\n",
    "combine_data['school_state_is_top_5'] = combine_data['school_state'].apply(lambda x:1 if x in school_state_sort_index else 0 )\n",
    "combine_data['school_state_is_tail_5'] = combine_data['school_state'].apply(lambda x:1 if x in school_state_tail_index else 0 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3、对essay进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_data['project_essay'] = combine_data.apply(lambda row:''.join([\n",
    "                             str(row['project_essay_1']),\n",
    "                             str(row['project_essay_2']),\n",
    "                             str(row['project_essay_3']),\n",
    "                             str(row['project_essay_4'])\n",
    "                             ]),axis=1)\n",
    "# combine_data['essay3_isnull'] = combine_data['project_essay_3'].apply(lambda x : 1 if x=='No_essay3' else 0)\n",
    "# combine_data['essay4_isnull'] = combine_data['project_essay_4'].apply(lambda x : 1 if x=='No_essay4' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4、对project_subject_catagory 和 project_subject_subcatagory标记前五名和后五名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#找出前5名索引,和后5名索引\n",
    "project_subject_catagory_head_index = train_data[['project_is_approved','project_subject_categories']].groupby(['project_subject_categories']).mean().sort_values(by='project_is_approved',ascending =False).head(5).index\n",
    "project_subject_catagory_tail_index = train_data[['project_is_approved','project_subject_categories']].groupby(['project_subject_categories']).mean().sort_values(by='project_is_approved',ascending =False).tail(5).index\n",
    "combine_data['project_subject_catagory_is_top_5'] = combine_data['project_subject_categories'].apply(lambda x:1 if x in project_subject_catagory_head_index else 0 )\n",
    "combine_data['project_subject_catagory_is_tail_5'] = combine_data['project_subject_categories'].apply(lambda x:1 if x in project_subject_catagory_tail_index else 0 )\n",
    "\n",
    "\n",
    "project_subject_subcatagory_head_index = train_data[['project_is_approved','project_subject_subcategories']].groupby(['project_subject_subcategories']).mean().sort_values(by='project_is_approved',ascending =False).head(5).index\n",
    "project_subject_subcatagory_tail_index = train_data[['project_is_approved','project_subject_subcategories']].groupby(['project_subject_subcategories']).mean().sort_values(by='project_is_approved',ascending =False).tail(5).index\n",
    "combine_data['project_subject_subcatagory_is_top_5'] = combine_data['project_subject_subcategories'].apply(lambda x:1 if x in project_subject_subcatagory_head_index else 0 )\n",
    "combine_data['project_subject_subcatagory_is_tail_5'] = combine_data['project_subject_subcategories'].apply(lambda x:1 if x in project_subject_subcatagory_tail_index else 0 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5、提取essay中的长度特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_length_from_essay(data):\n",
    "    data['project_title_len'] = data['project_title'].apply(lambda x:len(str(x)))\n",
    "    data['project_essay1_len'] = data['project_essay_1'].apply(lambda x:len(str(x)))\n",
    "    data['project_essay2_len'] = data['project_essay_2'].apply(lambda x:len(str(x)))\n",
    "    data['project_essay3_len'] = data['project_essay_3'].apply(lambda x:len(str(x)))\n",
    "    data['project_essay4_len'] = data['project_essay_4'].apply(lambda x:len(str(x)))\n",
    "    data['project_resource_summary_len'] = data['project_resource_summary'].apply(lambda x:len(str(x)))\n",
    "    data['resource_description_len'] = data['resource_description'].apply(lambda x:len(str(x)))\n",
    "    \n",
    "    data['project_title_word_len'] = data['project_title'].apply(lambda x:len(str(x).split(' ')))\n",
    "    data['project_essay1_word_len'] = data['project_essay_1'].apply(lambda x:len(str(x).split(' ')))\n",
    "    data['project_essay2_word_len'] = data['project_essay_2'].apply(lambda x:len(str(x).split(' ')))\n",
    "    data['project_essay3_word_len'] = data['project_essay_3'].apply(lambda x:len(str(x).split(' ')))\n",
    "    data['project_essay4_word_len'] = data['project_essay_4'].apply(lambda x:len(str(x).split(' ')))\n",
    "    data['project_resource_summary_word_len'] = data['project_resource_summary'].apply(lambda x:len(str(x).split(' ')))\n",
    "    data['resource_description_word_len'] = data['resource_description'].apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "    \n",
    "extract_length_from_essay(combine_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6、处理时间特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理时间特征\n",
      "处理完成\n"
     ]
    }
   ],
   "source": [
    "def extract_time_features(data):\n",
    "    print(u'开始处理时间特征')\n",
    "    timestamp = pd.to_datetime(data['project_submitted_datetime'])\n",
    "    data['year'] = timestamp.dt.year\n",
    "    data['month'] = timestamp.dt.month\n",
    "    data['day'] = timestamp.dt.day\n",
    "    data['weekday'] = timestamp.dt.weekday\n",
    "    data['hour'] = timestamp.dt.hour\n",
    "    data['minute'] = timestamp.dt.minute\n",
    "    data['second'] = timestamp.dt.second\n",
    "    print(u'处理完成')\n",
    "extract_time_features(combine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在提取情感信息\n",
      "project_title 情感提取完毕\n",
      "project_essay 情感提取完毕\n",
      "project_resource_summary 情感提取完毕\n",
      "resource_description 情感提取完毕\n",
      "情感特征提取完毕\n"
     ]
    }
   ],
   "source": [
    "textColumns = ['project_title','project_essay',\n",
    "               'project_resource_summary','resource_description']\n",
    "def getSentiment(sent):\n",
    "    Text = TextBlob(sent).sentiment\n",
    "    return (Text.polarity ,Text.subjectivity)\n",
    "\n",
    "def extract_sentimental_features(data):\n",
    "    print('正在提取情感信息')\n",
    "    for col in textColumns:\n",
    "        temp = np.array(list(map(getSentiment,data[col])))\n",
    "        data[col+'_pol'] = temp[:,0]\n",
    "        data[col+'_sub'] = temp[:,1]\n",
    "        print('%s 情感提取完毕'%col)\n",
    "    print('情感特征提取完毕')\n",
    "extract_sentimental_features(combine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feature_index = combine_data.select_dtypes(exclude='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feature_index = ['teacher_number_of_previously_posted_projects',\n",
    "       'total_price', 'mean_price', 'quantity_count', 'quantity_sum',\n",
    "       'project_title_len',\n",
    "       'project_essay1_len', 'project_essay2_len', 'project_essay3_len',\n",
    "       'project_essay4_len', 'project_resource_summary_len',\n",
    "       'resource_description_len', 'project_title_word_len',\n",
    "       'project_essay1_word_len', 'project_essay2_word_len',\n",
    "       'project_essay3_word_len', 'project_essay4_word_len',\n",
    "       'project_resource_summary_word_len', 'resource_description_word_len',\n",
    "        ]\n",
    "Train_numeric = combine_data.loc[combine_data.is_train_data==1,:][numeric_feature_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = 10\n",
    "index = [np.random.randint(0,Train_numeric.shape[0],int(Train_numeric.shape[0]/cv))\\\n",
    "         for k in range(cv)]\n",
    "\n",
    "#10次交叉验证\n",
    "Corr = {}\n",
    "\n",
    "for c in numeric_feature_index:\n",
    "    C1 ,P1 = np.nanmean([pearsonr(train_y[index[k]],(1+Train_numeric[c].iloc[index[k]]))\n",
    "                         for k in range(cv)],axis=0)\n",
    "    C2 ,P2 = np.nanmean([pearsonr(train_y[index[k]],1/(1+Train_numeric[c].iloc[index[k]]))\n",
    "                         for k in range(cv)],axis=0)\n",
    "    if P2<P1:\n",
    "        combine_data[c] =1/(1+ combine_data[c])\n",
    "        Corr[c] = [C2,P2]\n",
    "    else:\n",
    "        combine_data[c] = combine_data[c]+1\n",
    "        Corr[c] = [C1,P1]\n",
    "\n",
    "polyCol = []\n",
    "thrP =0.01\n",
    "thrC =0.02\n",
    "\n",
    "for i,c1 in enumerate(numeric_feature_index[:-1]):\n",
    "    C1,P1 = Corr[c1]\n",
    "    for c2 in numeric_feature_index[i+1:]:\n",
    "        C2,P2 =Corr[c2]\n",
    "        V = Train_numeric[c1]*Train_numeric[c2].values\n",
    "        C,P =np.nanmean([pearsonr(train_y[index[k]],V[index[k]]) for k in range(cv)],axis=0)\n",
    "        if P<thrP and abs(C) - max(abs(C1),abs(C2)) >thrC:\n",
    "            combine_data[c1+'_'+c2+'_poly'] = combine_data[c1]*combine_data[c2]\n",
    "            polyCol.append(c1+'_'+c2+'_poly')\n",
    "            print(c1 + '_' + c2, '\\t\\t(%g, %g)\\t(%g, %g)\\t(%g, %g)' % (C1, P1, C2, P2, C, P))\n",
    "\n",
    "del Train_numeric\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_catagory_features(data,cat):\n",
    "    vectorizer = CountVectorizer(binary=True,\n",
    "                                 ngram_range=(1,1),\n",
    "                                 tokenizer=lambda x :[word.strip() for word in x.split(',')])\n",
    "    for i,col in enumerate(cat):\n",
    "        vec = vectorizer.fit_transform(data[col].fillna(''))\n",
    "        if i==0:\n",
    "            cat_features = vec\n",
    "        else:\n",
    "            cat_features = hstack((cat_features ,vec))\n",
    "        del vec\n",
    "        gc.collect()\n",
    "    return cat_features\n",
    "\n",
    "cat_features = extract_catagory_features\\\n",
    "    (combine_data,['school_state','project_subject_categories','project_subject_subcategories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCatFeatures(T, Col):\n",
    "    vectorizer = CountVectorizer(binary=True,\n",
    "                                 ngram_range=(1,1),\n",
    "                                 tokenizer=lambda x:[a.strip() for a in x.split(',')])\n",
    "    return vectorizer.fit_transform(T[Col].fillna(''))\n",
    "\n",
    "X_pgc = getCatFeatures(combine_data, 'project_grade_category')\n",
    "X_psc = getCatFeatures(combine_data, 'project_subject_categories')\n",
    "X_pssc = getCatFeatures(combine_data, 'project_subject_subcategories')\n",
    "\n",
    "X_cat = hstack((X_pgc, X_psc, X_pssc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= pd.DataFrame(X)\n",
    "combine_data = pd.concat([combine_data,X],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 260115 entries, 0 to 260114\n",
      "Columns: 101 entries, id to 42\n",
      "dtypes: float64(17), int64(67), object(17)\n",
      "memory usage: 202.4+ MB\n"
     ]
    }
   ],
   "source": [
    "combine_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7、处理文字特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "cols = ['project_title','project_essay','project_resource_summary']\n",
    "n_features = [400,2000,400]\n",
    "\n",
    "print(u'开始进行文本处理')\n",
    "for c_i,c in tqdm(enumerate(cols)):\n",
    "    tfidf = TfidfVectorizer(max_features=n_features[c_i],norm='l2')\n",
    "    tfidf.fit(combine_data[c])\n",
    "    tfidf_combine = np.array(tfidf.transform(combine_data[c]).toarray(),dtype=np.float16)\n",
    "    \n",
    "    for j in range(n_features[c_i]):\n",
    "        combine_data[c+'_tfidf_'+str(j)] = tfidf_combine[:,j]\n",
    "    del tfidf,tfidf_combine\n",
    "    gc.collect()\n",
    "print(u'完成文本特征提取')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8、 下面进行一些catagory特征的编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catagory_feature = [\n",
    "    'teacher_id',\n",
    "    'teacher_prefix',\n",
    "    'school_state',\n",
    "    'project_grade_category',\n",
    "    'project_subject_categories',\n",
    "    'project_subject_subcategories',\n",
    "    'gender'\n",
    "]\n",
    "print(u'开始编码')\n",
    "for i,col in enumerate(catagory_feature):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(combine_data[col].astype(str))\n",
    "    combine_data[col] = encoder.transform(combine_data[col].astype(str))\n",
    "    del encoder\n",
    "    gc.collect()\n",
    "print(u'完成编码')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9、最后丢掉一些冗余特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop_columns = [\n",
    "    'id',\n",
    "    'project_submitted_datetime',\n",
    "    'project_title',\n",
    "    'project_essay_1', \n",
    "    'project_essay_2',\n",
    "     'project_essay_3', \n",
    "    'project_essay_4', \n",
    "    'project_resource_summary',\n",
    "    'project_essay'\n",
    "]\n",
    "\n",
    "combine_data = combine_data.drop(labels=drop_columns,axis=1,errors='ignore')\n",
    "float64_index = combine_data.select_dtypes(include=np.float64).columns\n",
    "combine_data[float64_index] = combine_data[float64_index].astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分离训练集和测试集\n",
    "\n",
    "train_X = combine_data.loc[combine_data.is_train_data ==1,:].drop('is_train_data',axis=1,errors='ignore')\n",
    "test_X = combine_data.loc[combine_data.is_train_data != 1 ,:].drop('is_train_data',axis=1,errors='ignore')\n",
    "train_y = train_data['project_is_approved']\n",
    "id_test = test_data['id'].values\n",
    "del train_data,test_data,resource,combine_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 至以上步骤我们已经完成了特征工程，下面进行模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立模型\n",
    "\n",
    "feature_names = list(train_X.columns)\n",
    "cnt = 0 \n",
    "p_buf = []\n",
    "n_splits = 5\n",
    "n_repeats = 1\n",
    "kf = RepeatedKFold(n_splits=n_splits,n_repeats=n_repeats,random_state=0)\n",
    "auc_buf=[]\n",
    "\n",
    "for train_index,valid_index in kf.split(train_X):\n",
    "    print('Fold {}/{}'.format(cnt+1,n_splits))\n",
    "    lgb_params ={\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective':'binary',\n",
    "        'metric':'auc',\n",
    "        'max_depth':14,\n",
    "        'num_leaves':31,\n",
    "        'learning_rate':0.025,\n",
    "        'feature_fraction':0.85,\n",
    "        'bagging_fraction':0.85,\n",
    "        'bagging_freq':5,\n",
    "        'verbose':0,\n",
    "        'lambda_l2':1.0,\n",
    "        'num_threads': 1,\n",
    "        'min_gain_to_split':0,\n",
    "    }\n",
    "    lgb_train = lgb.Dataset(\n",
    "    train_X.loc[train_index],\n",
    "    train_y.loc[valid_index],\n",
    "    feature_name=feature_names)\n",
    "    \n",
    "    lgb_train.raw_data = None\n",
    "    \n",
    "    lgb_valid = lgb.Dataset(\n",
    "    train_X.loc[valid_index],\n",
    "    train_y.loc[valid_index])\n",
    "    \n",
    "    lgb_valid.raw_data= None\n",
    "    \n",
    "    lgb_clf = lgb.train(\n",
    "    lgb_params,\n",
    "    lgb_train,\n",
    "    num_boost_round=10000,\n",
    "    valid_sets=[lgb_train,lgb_valid],\n",
    "    early_stopping_rounds=100,\n",
    "    verbose_eval=100\n",
    "    )\n",
    "    \n",
    "    if cnt==0:\n",
    "        importance = lgb_clf.feature_importance()\n",
    "        model_fnames = lgb_clf.feature_name()\n",
    "        tuples = sorted(zip(model_fnames, importance), key=lambda x: x[1])[::-1]\n",
    "        tuples = [x for x in tuples if x[1]>0]\n",
    "        print('Important features')\n",
    "        for i in range(60):\n",
    "            if i< len(tuples):\n",
    "                print(tuples[i])\n",
    "            else:\n",
    "                break\n",
    "        del importance,model_fnames,tuples\n",
    "        gc.collect()\n",
    "    \n",
    "    p = lgb_clf.predict(train_X.loc[valid_index],num_iteration = lgb_clf.best_iteration)\n",
    "    auc = roc_auc_score(train_y.loc[valid_index],p)\n",
    "    \n",
    "    print('{} AUC: {}'.format(cnt,auc))\n",
    "    \n",
    "    p = lgb_clf.predict(test_X,num_iteration = lgb_clf.best_iteration )\n",
    "    if len(p_buf) == 0:\n",
    "        p_buf = np.array(p,dtype=np.float16)\n",
    "    else:\n",
    "        p_buf += np.array(p, dtype=np.float16)\n",
    "    auc_buf.append(auc)\n",
    "    \n",
    "    cnt += 1\n",
    "    \n",
    "#     if cnt>0:\n",
    "#         break\n",
    "        \n",
    "    del lgb_clf,lgb_train,lgb_valid,p\n",
    "    gc.collect()\n",
    "\n",
    "auc_mean = np.mean(auc_buf)\n",
    "auc_std = np.std(auc_buf)\n",
    "print('AUC = {:.6f} +/- {:.6f}'.format(auc_mean,auc_std))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
