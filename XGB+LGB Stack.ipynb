{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer ,CountVectorizer\n",
    "from sklearn.model_selection import KFold,RepeatedKFold\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import defaultdict,Counter\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "from textblob import TextBlob\n",
    "import xgboost as xgb\n",
    "from multiprocessing import Pool\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.sparse import  hstack\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem  import PorterStemmer\n",
    "\n",
    "\n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei']\n",
    "mpl.rcParams['font.family']='sans-serif'\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "resource = pd.read_csv('data/resources.csv',low_memory=False)\n",
    "train_data = pd.read_csv('data/train.csv',low_memory=False)\n",
    "test_data = pd.read_csv('data/test.csv',low_memory=False)\n",
    "train_y = train_data['project_is_approved']\n",
    "id_test = test_data['id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['is_train_data'] = 1\n",
    "test_data['is_train_data'] = 0\n",
    "train_X = train_data.drop('project_is_approved',axis=1,inplace=False)\n",
    "test_X = test_data\n",
    "combine_data = pd.concat([train_X,test_X],axis=0,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从 resource文件中产生更多特征\n",
    "resource['total_price'] = resource['quantity'] * resource['price']\n",
    "#产生 total_price特征\n",
    "new_features = resource.groupby(['id'],as_index=False)[['total_price']].sum()\n",
    "combine_data = pd.merge(combine_data,new_features,how='left',on='id')\n",
    "\n",
    "new_features = resource.groupby(['id'],as_index=False)[['total_price']].mean()\n",
    "new_features = new_features.rename(columns={'total_price':'mean_price'})\n",
    "combine_data = pd.merge(combine_data,new_features,how='left',on='id')\n",
    "\n",
    "new_features = resource.groupby(['id'],as_index=False)[['quantity']].count()\n",
    "new_features = new_features.rename(columns={'quantity':'quantity_count'})\n",
    "combine_data = pd.merge(combine_data,new_features,how='left',on='id')\n",
    "\n",
    "new_features = resource.groupby(['id'],as_index=False)[['quantity']].sum()\n",
    "new_features = new_features.rename(columns={'quantity':'quantity_sum'})\n",
    "combine_data = pd.merge(combine_data,new_features,how='left',on='id')\n",
    "\n",
    "\n",
    "new_features = resource.groupby(['id'],as_index = False).agg({'description':lambda x:''.join(x.values.astype(str))}).rename(\n",
    "    columns = {'description':'resource_description'})\n",
    "combine_data = pd.merge(combine_data,new_features,how='left',on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_data['teacher_prefix']=combine_data['teacher_prefix'].fillna(combine_data['teacher_prefix'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gender(data):\n",
    "    if data == 'Mr.':\n",
    "        return 'male'\n",
    "    elif  data=='Mrs.' or data=='Ms.':\n",
    "        return 'female'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "combine_data ['gender'] = combine_data['teacher_prefix'].apply(add_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_state_sort_index = train_data[['project_is_approved','school_state']].groupby(['school_state']).mean().sort_values(by='project_is_approved',ascending =False).head(5).index\n",
    "school_state_tail_index = train_data[['project_is_approved','school_state']].groupby(['school_state']).mean().sort_values(by='project_is_approved',ascending =False).tail(5).index\n",
    "combine_data['school_state_is_top_5'] = combine_data['school_state'].apply(lambda x:1 if x in school_state_sort_index else 0 )\n",
    "combine_data['school_state_is_tail_5'] = combine_data['school_state'].apply(lambda x:1 if x in school_state_tail_index else 0 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_data['project_essay'] = combine_data.apply(lambda row:''.join([\n",
    "                             str(row['project_essay_1']),\n",
    "                             str(row['project_essay_2']),\n",
    "                             str(row['project_essay_3']),\n",
    "                             str(row['project_essay_4'])\n",
    "                             ]),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_subject_catagory_head_index = train_data[['project_is_approved','project_subject_categories']].groupby(['project_subject_categories']).mean().sort_values(by='project_is_approved',ascending =False).head(5).index\n",
    "project_subject_catagory_tail_index = train_data[['project_is_approved','project_subject_categories']].groupby(['project_subject_categories']).mean().sort_values(by='project_is_approved',ascending =False).tail(5).index\n",
    "combine_data['project_subject_catagory_is_top_5'] = combine_data['project_subject_categories'].apply(lambda x:1 if x in project_subject_catagory_head_index else 0 )\n",
    "combine_data['project_subject_catagory_is_tail_5'] = combine_data['project_subject_categories'].apply(lambda x:1 if x in project_subject_catagory_tail_index else 0 )\n",
    "\n",
    "\n",
    "project_subject_subcatagory_head_index = train_data[['project_is_approved','project_subject_subcategories']].groupby(['project_subject_subcategories']).mean().sort_values(by='project_is_approved',ascending =False).head(5).index\n",
    "project_subject_subcatagory_tail_index = train_data[['project_is_approved','project_subject_subcategories']].groupby(['project_subject_subcategories']).mean().sort_values(by='project_is_approved',ascending =False).tail(5).index\n",
    "combine_data['project_subject_subcatagory_is_top_5'] = combine_data['project_subject_subcategories'].apply(lambda x:1 if x in project_subject_subcatagory_head_index else 0 )\n",
    "combine_data['project_subject_subcatagory_is_tail_5'] = combine_data['project_subject_subcategories'].apply(lambda x:1 if x in project_subject_subcatagory_tail_index else 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_length_from_essay(data):\n",
    "    data['project_title_len'] = data['project_title'].apply(lambda x:len(str(x)))\n",
    "    data['project_essay1_len'] = data['project_essay_1'].apply(lambda x:len(str(x)))\n",
    "    data['project_essay2_len'] = data['project_essay_2'].apply(lambda x:len(str(x)))\n",
    "    data['project_essay3_len'] = data['project_essay_3'].apply(lambda x:len(str(x)))\n",
    "    data['project_essay4_len'] = data['project_essay_4'].apply(lambda x:len(str(x)))\n",
    "    data['project_resource_summary_len'] = data['project_resource_summary'].apply(lambda x:len(str(x)))\n",
    "    data['resource_description_len'] = data['resource_description'].apply(lambda x:len(str(x)))\n",
    "\n",
    "    data['project_title_word_len'] = data['project_title'].apply(lambda x:len(str(x).split(' ')))\n",
    "    data['project_essay1_word_len'] = data['project_essay_1'].apply(lambda x:len(str(x).split(' ')))\n",
    "    data['project_essay2_word_len'] = data['project_essay_2'].apply(lambda x:len(str(x).split(' ')))\n",
    "    data['project_essay3_word_len'] = data['project_essay_3'].apply(lambda x:len(str(x).split(' ')))\n",
    "    data['project_essay4_word_len'] = data['project_essay_4'].apply(lambda x:len(str(x).split(' ')))\n",
    "    data['project_resource_summary_word_len'] = data['project_resource_summary'].apply(lambda x:len(str(x).split(' ')))\n",
    "    data['resource_description_word_len'] = data['resource_description'].apply(lambda x: len(str(x).split(' ')))\n",
    "    \n",
    "extract_length_from_essay(combine_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理时间特征\n",
      "处理完成\n"
     ]
    }
   ],
   "source": [
    "def extract_time_features(data):\n",
    "    print(u'开始处理时间特征')\n",
    "    timestamp = pd.to_datetime(data['project_submitted_datetime'])\n",
    "    data['year'] = timestamp.dt.year\n",
    "    data['month'] = timestamp.dt.month\n",
    "    data['day'] = timestamp.dt.day\n",
    "    data['weekday'] = timestamp.dt.weekday\n",
    "    data['hour'] = timestamp.dt.hour\n",
    "    data['minute'] = timestamp.dt.minute\n",
    "    data['second'] = timestamp.dt.second\n",
    "    print(u'处理完成')\n",
    "extract_time_features(combine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在提取情感信息\n",
      "project_title 情感提取完毕\n",
      "project_essay 情感提取完毕\n",
      "project_resource_summary 情感提取完毕\n",
      "resource_description 情感提取完毕\n",
      "情感特征提取完毕\n"
     ]
    }
   ],
   "source": [
    "textColumns = ['project_title','project_essay',\n",
    "               'project_resource_summary','resource_description']\n",
    "\n",
    "def getSentiment(sent):\n",
    "    Text = TextBlob(sent).sentiment\n",
    "    return (Text.polarity ,Text.subjectivity)\n",
    "\n",
    "def extract_sentimental_features(data):\n",
    "    print('正在提取情感信息')\n",
    "    for col in textColumns:\n",
    "        temp = np.array(list(map(getSentiment,data[col])))\n",
    "        data[col+'_pol'] = temp[:,0]\n",
    "        data[col+'_sub'] = temp[:,1]\n",
    "        print('%s 情感提取完毕'%col)\n",
    "    print('情感特征提取完毕')\n",
    "extract_sentimental_features(combine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在提取重点词汇....\n",
      "project_title 关键词: ! 提取完毕\n",
      "project_title 关键词: \\? 提取完毕\n",
      "project_title 关键词: @ 提取完毕\n",
      "project_title 关键词: # 提取完毕\n",
      "project_title 关键词: \\$ 提取完毕\n",
      "project_title 关键词: % 提取完毕\n",
      "project_title 关键词: & 提取完毕\n",
      "project_title 关键词: \\* 提取完毕\n",
      "project_title 关键词: \\( 提取完毕\n",
      "project_title 关键词: \\[ 提取完毕\n",
      "project_title 关键词: \\{ 提取完毕\n",
      "project_title 关键词: \\| 提取完毕\n",
      "project_title 关键词: - 提取完毕\n",
      "project_title 关键词: _ 提取完毕\n",
      "project_title 关键词: = 提取完毕\n",
      "project_title 关键词: \\+ 提取完毕\n",
      "project_title 关键词: \\. 提取完毕\n",
      "project_title 关键词: : 提取完毕\n",
      "project_title 关键词: ; 提取完毕\n",
      "project_title 关键词: , 提取完毕\n",
      "project_title 关键词: / 提取完毕\n",
      "project_title 关键词: \\\\r 提取完毕\n",
      "project_title 关键词: \\\\t 提取完毕\n",
      "project_title 关键词: \\\" 提取完毕\n",
      "project_title 关键词: \\.\\.\\. 提取完毕\n",
      "project_title 关键词: etc 提取完毕\n",
      "project_title 关键词: http 提取完毕\n",
      "project_title 关键词: poor 提取完毕\n",
      "project_title 关键词: military 提取完毕\n",
      "project_title 关键词: traditional 提取完毕\n",
      "project_title 关键词: charter 提取完毕\n",
      "project_title 关键词: head start 提取完毕\n",
      "project_title 关键词: magnet 提取完毕\n",
      "project_title 关键词: year-round 提取完毕\n",
      "project_title 关键词: alternative 提取完毕\n",
      "project_title 关键词: art 提取完毕\n",
      "project_title 关键词: book 提取完毕\n",
      "project_title 关键词: basics 提取完毕\n",
      "project_title 关键词: computer 提取完毕\n",
      "project_title 关键词: laptop 提取完毕\n",
      "project_title 关键词: tablet 提取完毕\n",
      "project_title 关键词: kit 提取完毕\n",
      "project_title 关键词: game 提取完毕\n",
      "project_title 关键词: seat 提取完毕\n",
      "project_title 关键词: food 提取完毕\n",
      "project_title 关键词: cloth 提取完毕\n",
      "project_title 关键词: hygiene 提取完毕\n",
      "project_title 关键词: instraction 提取完毕\n",
      "project_title 关键词: technolog 提取完毕\n",
      "project_title 关键词: lab 提取完毕\n",
      "project_title 关键词: equipment 提取完毕\n",
      "project_title 关键词: music 提取完毕\n",
      "project_title 关键词: instrument 提取完毕\n",
      "project_title 关键词: nook 提取完毕\n",
      "project_title 关键词: desk 提取完毕\n",
      "project_title 关键词: storage 提取完毕\n",
      "project_title 关键词: sport 提取完毕\n",
      "project_title 关键词: exercise 提取完毕\n",
      "project_title 关键词: trip 提取完毕\n",
      "project_title 关键词: visitor 提取完毕\n",
      "project_title 关键词: my students 提取完毕\n",
      "project_title 关键词: our students 提取完毕\n",
      "project_title 关键词: my class 提取完毕\n",
      "project_title 关键词: our class 提取完毕\n",
      "project_essay 关键词: ! 提取完毕\n",
      "project_essay 关键词: \\? 提取完毕\n",
      "project_essay 关键词: @ 提取完毕\n",
      "project_essay 关键词: # 提取完毕\n",
      "project_essay 关键词: \\$ 提取完毕\n",
      "project_essay 关键词: % 提取完毕\n",
      "project_essay 关键词: & 提取完毕\n",
      "project_essay 关键词: \\* 提取完毕\n",
      "project_essay 关键词: \\( 提取完毕\n",
      "project_essay 关键词: \\[ 提取完毕\n",
      "project_essay 关键词: \\{ 提取完毕\n",
      "project_essay 关键词: \\| 提取完毕\n",
      "project_essay 关键词: - 提取完毕\n",
      "project_essay 关键词: _ 提取完毕\n",
      "project_essay 关键词: = 提取完毕\n",
      "project_essay 关键词: \\+ 提取完毕\n",
      "project_essay 关键词: \\. 提取完毕\n",
      "project_essay 关键词: : 提取完毕\n",
      "project_essay 关键词: ; 提取完毕\n",
      "project_essay 关键词: , 提取完毕\n",
      "project_essay 关键词: / 提取完毕\n",
      "project_essay 关键词: \\\\r 提取完毕\n",
      "project_essay 关键词: \\\\t 提取完毕\n",
      "project_essay 关键词: \\\" 提取完毕\n",
      "project_essay 关键词: \\.\\.\\. 提取完毕\n",
      "project_essay 关键词: etc 提取完毕\n",
      "project_essay 关键词: http 提取完毕\n",
      "project_essay 关键词: poor 提取完毕\n",
      "project_essay 关键词: military 提取完毕\n",
      "project_essay 关键词: traditional 提取完毕\n",
      "project_essay 关键词: charter 提取完毕\n",
      "project_essay 关键词: head start 提取完毕\n",
      "project_essay 关键词: magnet 提取完毕\n",
      "project_essay 关键词: year-round 提取完毕\n",
      "project_essay 关键词: alternative 提取完毕\n",
      "project_essay 关键词: art 提取完毕\n",
      "project_essay 关键词: book 提取完毕\n",
      "project_essay 关键词: basics 提取完毕\n",
      "project_essay 关键词: computer 提取完毕\n",
      "project_essay 关键词: laptop 提取完毕\n",
      "project_essay 关键词: tablet 提取完毕\n",
      "project_essay 关键词: kit 提取完毕\n",
      "project_essay 关键词: game 提取完毕\n",
      "project_essay 关键词: seat 提取完毕\n",
      "project_essay 关键词: food 提取完毕\n",
      "project_essay 关键词: cloth 提取完毕\n",
      "project_essay 关键词: hygiene 提取完毕\n",
      "project_essay 关键词: instraction 提取完毕\n",
      "project_essay 关键词: technolog 提取完毕\n",
      "project_essay 关键词: lab 提取完毕\n",
      "project_essay 关键词: equipment 提取完毕\n",
      "project_essay 关键词: music 提取完毕\n",
      "project_essay 关键词: instrument 提取完毕\n",
      "project_essay 关键词: nook 提取完毕\n",
      "project_essay 关键词: desk 提取完毕\n",
      "project_essay 关键词: storage 提取完毕\n",
      "project_essay 关键词: sport 提取完毕\n",
      "project_essay 关键词: exercise 提取完毕\n",
      "project_essay 关键词: trip 提取完毕\n",
      "project_essay 关键词: visitor 提取完毕\n",
      "project_essay 关键词: my students 提取完毕\n",
      "project_essay 关键词: our students 提取完毕\n",
      "project_essay 关键词: my class 提取完毕\n",
      "project_essay 关键词: our class 提取完毕\n",
      "project_resource_summary 关键词: ! 提取完毕\n",
      "project_resource_summary 关键词: \\? 提取完毕\n",
      "project_resource_summary 关键词: @ 提取完毕\n",
      "project_resource_summary 关键词: # 提取完毕\n",
      "project_resource_summary 关键词: \\$ 提取完毕\n",
      "project_resource_summary 关键词: % 提取完毕\n",
      "project_resource_summary 关键词: & 提取完毕\n",
      "project_resource_summary 关键词: \\* 提取完毕\n",
      "project_resource_summary 关键词: \\( 提取完毕\n",
      "project_resource_summary 关键词: \\[ 提取完毕\n",
      "project_resource_summary 关键词: \\{ 提取完毕\n",
      "project_resource_summary 关键词: \\| 提取完毕\n",
      "project_resource_summary 关键词: - 提取完毕\n",
      "project_resource_summary 关键词: _ 提取完毕\n",
      "project_resource_summary 关键词: = 提取完毕\n",
      "project_resource_summary 关键词: \\+ 提取完毕\n",
      "project_resource_summary 关键词: \\. 提取完毕\n",
      "project_resource_summary 关键词: : 提取完毕\n",
      "project_resource_summary 关键词: ; 提取完毕\n",
      "project_resource_summary 关键词: , 提取完毕\n",
      "project_resource_summary 关键词: / 提取完毕\n",
      "project_resource_summary 关键词: \\\\r 提取完毕\n",
      "project_resource_summary 关键词: \\\\t 提取完毕\n",
      "project_resource_summary 关键词: \\\" 提取完毕\n",
      "project_resource_summary 关键词: \\.\\.\\. 提取完毕\n",
      "project_resource_summary 关键词: etc 提取完毕\n",
      "project_resource_summary 关键词: http 提取完毕\n",
      "project_resource_summary 关键词: poor 提取完毕\n",
      "project_resource_summary 关键词: military 提取完毕\n",
      "project_resource_summary 关键词: traditional 提取完毕\n",
      "project_resource_summary 关键词: charter 提取完毕\n",
      "project_resource_summary 关键词: head start 提取完毕\n",
      "project_resource_summary 关键词: magnet 提取完毕\n",
      "project_resource_summary 关键词: year-round 提取完毕\n",
      "project_resource_summary 关键词: alternative 提取完毕\n",
      "project_resource_summary 关键词: art 提取完毕\n",
      "project_resource_summary 关键词: book 提取完毕\n",
      "project_resource_summary 关键词: basics 提取完毕\n",
      "project_resource_summary 关键词: computer 提取完毕\n",
      "project_resource_summary 关键词: laptop 提取完毕\n",
      "project_resource_summary 关键词: tablet 提取完毕\n",
      "project_resource_summary 关键词: kit 提取完毕\n",
      "project_resource_summary 关键词: game 提取完毕\n",
      "project_resource_summary 关键词: seat 提取完毕\n",
      "project_resource_summary 关键词: food 提取完毕\n",
      "project_resource_summary 关键词: cloth 提取完毕\n",
      "project_resource_summary 关键词: hygiene 提取完毕\n",
      "project_resource_summary 关键词: instraction 提取完毕\n",
      "project_resource_summary 关键词: technolog 提取完毕\n",
      "project_resource_summary 关键词: lab 提取完毕\n",
      "project_resource_summary 关键词: equipment 提取完毕\n",
      "project_resource_summary 关键词: music 提取完毕\n",
      "project_resource_summary 关键词: instrument 提取完毕\n",
      "project_resource_summary 关键词: nook 提取完毕\n",
      "project_resource_summary 关键词: desk 提取完毕\n",
      "project_resource_summary 关键词: storage 提取完毕\n",
      "project_resource_summary 关键词: sport 提取完毕\n",
      "project_resource_summary 关键词: exercise 提取完毕\n",
      "project_resource_summary 关键词: trip 提取完毕\n",
      "project_resource_summary 关键词: visitor 提取完毕\n",
      "project_resource_summary 关键词: my students 提取完毕\n",
      "project_resource_summary 关键词: our students 提取完毕\n",
      "project_resource_summary 关键词: my class 提取完毕\n",
      "project_resource_summary 关键词: our class 提取完毕\n",
      "resource_description 关键词: ! 提取完毕\n",
      "resource_description 关键词: \\? 提取完毕\n",
      "resource_description 关键词: @ 提取完毕\n",
      "resource_description 关键词: # 提取完毕\n",
      "resource_description 关键词: \\$ 提取完毕\n",
      "resource_description 关键词: % 提取完毕\n",
      "resource_description 关键词: & 提取完毕\n",
      "resource_description 关键词: \\* 提取完毕\n",
      "resource_description 关键词: \\( 提取完毕\n",
      "resource_description 关键词: \\[ 提取完毕\n",
      "resource_description 关键词: \\{ 提取完毕\n",
      "resource_description 关键词: \\| 提取完毕\n",
      "resource_description 关键词: - 提取完毕\n",
      "resource_description 关键词: _ 提取完毕\n",
      "resource_description 关键词: = 提取完毕\n",
      "resource_description 关键词: \\+ 提取完毕\n",
      "resource_description 关键词: \\. 提取完毕\n",
      "resource_description 关键词: : 提取完毕\n",
      "resource_description 关键词: ; 提取完毕\n",
      "resource_description 关键词: , 提取完毕\n",
      "resource_description 关键词: / 提取完毕\n",
      "resource_description 关键词: \\\\r 提取完毕\n",
      "resource_description 关键词: \\\\t 提取完毕\n",
      "resource_description 关键词: \\\" 提取完毕\n",
      "resource_description 关键词: \\.\\.\\. 提取完毕\n",
      "resource_description 关键词: etc 提取完毕\n",
      "resource_description 关键词: http 提取完毕\n",
      "resource_description 关键词: poor 提取完毕\n",
      "resource_description 关键词: military 提取完毕\n",
      "resource_description 关键词: traditional 提取完毕\n",
      "resource_description 关键词: charter 提取完毕\n",
      "resource_description 关键词: head start 提取完毕\n",
      "resource_description 关键词: magnet 提取完毕\n",
      "resource_description 关键词: year-round 提取完毕\n",
      "resource_description 关键词: alternative 提取完毕\n",
      "resource_description 关键词: art 提取完毕\n",
      "resource_description 关键词: book 提取完毕\n",
      "resource_description 关键词: basics 提取完毕\n",
      "resource_description 关键词: computer 提取完毕\n",
      "resource_description 关键词: laptop 提取完毕\n",
      "resource_description 关键词: tablet 提取完毕\n",
      "resource_description 关键词: kit 提取完毕\n",
      "resource_description 关键词: game 提取完毕\n",
      "resource_description 关键词: seat 提取完毕\n",
      "resource_description 关键词: food 提取完毕\n",
      "resource_description 关键词: cloth 提取完毕\n",
      "resource_description 关键词: hygiene 提取完毕\n",
      "resource_description 关键词: instraction 提取完毕\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource_description 关键词: technolog 提取完毕\n",
      "resource_description 关键词: lab 提取完毕\n",
      "resource_description 关键词: equipment 提取完毕\n",
      "resource_description 关键词: music 提取完毕\n",
      "resource_description 关键词: instrument 提取完毕\n",
      "resource_description 关键词: nook 提取完毕\n",
      "resource_description 关键词: desk 提取完毕\n",
      "resource_description 关键词: storage 提取完毕\n",
      "resource_description 关键词: sport 提取完毕\n",
      "resource_description 关键词: exercise 提取完毕\n",
      "resource_description 关键词: trip 提取完毕\n",
      "resource_description 关键词: visitor 提取完毕\n",
      "resource_description 关键词: my students 提取完毕\n",
      "resource_description 关键词: our students 提取完毕\n",
      "resource_description 关键词: my class 提取完毕\n",
      "resource_description 关键词: our class 提取完毕\n",
      "关键词特征提取完毕\n"
     ]
    }
   ],
   "source": [
    "KeyChars = ['!', '\\?', '@', '#', '\\$', '%', '&', '\\*', '\\(', '\\[', '\\{', '\\|', '-', '_', '=', '\\+',\n",
    "            '\\.', ':', ';', ',', '/', '\\\\\\\\r', '\\\\\\\\t', '\\\\\"', '\\.\\.\\.', 'etc', 'http', 'poor',\n",
    "            'military', 'traditional', 'charter', 'head start', 'magnet', 'year-round', 'alternative',\n",
    "            'art', 'book', 'basics', 'computer', 'laptop', 'tablet', 'kit', 'game', 'seat',\n",
    "            'food', 'cloth', 'hygiene', 'instraction', 'technolog', 'lab', 'equipment',\n",
    "            'music', 'instrument', 'nook', 'desk', 'storage', 'sport', 'exercise', 'trip', 'visitor',\n",
    "            'my students', 'our students', 'my class', 'our class']\n",
    "\n",
    "def extract_keychar_features(data):\n",
    "    print('正在提取重点词汇....')\n",
    "    for col in textColumns:\n",
    "        for c in KeyChars:\n",
    "            data[col+'_'+c] = data[col].apply(lambda x:len(re.findall(c,x.lower())))\n",
    "            print('%s 关键词: %s 提取完毕'%(col,c))\n",
    "    print('关键词特征提取完毕')\n",
    "extract_keychar_features(combine_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始提取公共词特征....\n",
      "project_title 和 project_essay 公共词寻找完毕\n",
      "project_title 和 project_resource_summary 公共词寻找完毕\n",
      "project_title 和 resource_description 公共词寻找完毕\n",
      "project_essay 和 project_resource_summary 公共词寻找完毕\n",
      "project_essay 和 resource_description 公共词寻找完毕\n",
      "project_resource_summary 和 resource_description 公共词寻找完毕\n",
      "公共词特征提取完毕\n"
     ]
    }
   ],
   "source": [
    "def extract_common_word_features(data):\n",
    "    print('开始提取公共词特征....')\n",
    "    for i,col1 in enumerate(textColumns[:-1]):\n",
    "        for col2 in textColumns[i+1:]:\n",
    "            data['%s_%s_common'%(col1,col2)] = \\\n",
    "                data.apply(lambda row:len(set(re.split('\\W',row[col1].lower())).intersection(re.split('\\W',row[col2].lower()))),axis = 1)\n",
    "            print('%s 和 %s 公共词寻找完毕'%(col1,col2))\n",
    "    print('公共词特征提取完毕')\n",
    "extract_common_word_features(combine_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feature_index = ['teacher_number_of_previously_posted_projects',\n",
    "       'total_price', 'mean_price', 'quantity_count', 'quantity_sum',\n",
    "       'project_title_len',\n",
    "       'project_essay1_len', 'project_essay2_len', 'project_essay3_len',\n",
    "       'project_essay4_len', 'project_resource_summary_len',\n",
    "       'resource_description_len', 'project_title_word_len',\n",
    "       'project_essay1_word_len', 'project_essay2_word_len',\n",
    "       'project_essay3_word_len', 'project_essay4_word_len',\n",
    "       'project_resource_summary_word_len', 'resource_description_word_len',\n",
    "        ]\n",
    "\n",
    "#提取出训练数据\n",
    "Train_numeric = combine_data.loc[combine_data.is_train_data==1,:][numeric_feature_index]\n",
    "cv = 10\n",
    "index = [np.random.randint(0,Train_numeric.shape[0],int(Train_numeric.shape[0]/cv))\\\n",
    "         for k in range(cv)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corr = {}\n",
    "\n",
    "for c in numeric_feature_index:\n",
    "    C1 ,P1 = np.nanmean([pearsonr(train_y[index[k]],(1+Train_numeric[c].iloc[index[k]]))\n",
    "                         for k in range(cv)],axis=0)\n",
    "    C2 ,P2 = np.nanmean([pearsonr(train_y[index[k]],1/(1+Train_numeric[c].iloc[index[k]]))\n",
    "                         for k in range(cv)],axis=0)\n",
    "    if P2<P1:\n",
    "        combine_data[c] =1/(1+ combine_data[c])\n",
    "        Corr[c] = [C2,P2]\n",
    "    else:\n",
    "        combine_data[c] = combine_data[c]+1\n",
    "        Corr[c] = [C1,P1]\n",
    "\n",
    "polyCol = []\n",
    "thrP =0.01\n",
    "thrC =0.02\n",
    "\n",
    "for i,c1 in enumerate(numeric_feature_index[:-1]):\n",
    "    C1,P1 = Corr[c1]\n",
    "    for c2 in numeric_feature_index[i+1:]:\n",
    "        C2,P2 =Corr[c2]\n",
    "        V = Train_numeric[c1]*Train_numeric[c2].values\n",
    "        C,P =np.nanmean([pearsonr(train_y[index[k]],V[index[k]]) for k in range(cv)],axis=0)\n",
    "        if P<thrP and abs(C) - max(abs(C1),abs(C2)) >thrC:\n",
    "            combine_data[c1+'_'+c2+'_poly'] = combine_data[c1]*combine_data[c2]\n",
    "            polyCol.append(c1+'_'+c2+'_poly')\n",
    "            print(c1 + '_' + c2, '\\t\\t(%g, %g)\\t(%g, %g)\\t(%g, %g)' % (C1, P1, C2, P2, C, P))\n",
    "\n",
    "del Train_numeric\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始进行文本处理\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [02:54, 58.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成文本特征提取\n"
     ]
    }
   ],
   "source": [
    "cols = ['project_title','project_essay','project_resource_summary']\n",
    "n_features = [400,2000,400]\n",
    "\n",
    "print(u'开始进行文本处理')\n",
    "for c_i,c in tqdm(enumerate(cols)):\n",
    "    tfidf = TfidfVectorizer(max_features=n_features[c_i],norm='l2')\n",
    "    tfidf.fit(combine_data[c])\n",
    "    tfidf_combine = np.array(tfidf.transform(combine_data[c]).toarray(),dtype=np.float16)\n",
    "    \n",
    "    for j in range(n_features[c_i]):\n",
    "        combine_data[c+'_tfidf_'+str(j)] = tfidf_combine[:,j]\n",
    "    del tfidf,tfidf_combine\n",
    "    gc.collect()\n",
    "print(u'完成文本特征提取')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 8、 下面进行一些catagory特征的编码\n",
    "def extract_catagory_features(data,cat):\n",
    "    vectorizer = CountVectorizer(binary=True,\n",
    "                                 ngram_range=(1,1),\n",
    "                                 tokenizer=lambda x :[word.strip() for word in x.split(',')])\n",
    "    for i,col in enumerate(cat):\n",
    "        vec = vectorizer.fit_transform(data[col].fillna(''))\n",
    "        if i==0:\n",
    "            cat_features = vec\n",
    "        else:\n",
    "            cat_features = hstack((cat_features ,vec))\n",
    "        del vec\n",
    "        gc.collect()\n",
    "    return cat_features\n",
    "\n",
    "#此时的输出为稀疏矩阵\n",
    "cat_feat = ['project_subject_categories','project_subject_subcategories']\n",
    "cat_features = extract_catagory_features\\\n",
    "    (combine_data,cat_feat)\n",
    "cat_features = cat_features.toarray()\n",
    "cat_features = pd.DataFrame(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始编码\n",
      "完成编码\n"
     ]
    }
   ],
   "source": [
    "catagory_feature = [\n",
    "    'teacher_id',\n",
    "    'teacher_prefix',\n",
    "    'gender',\n",
    "    'school_state',\n",
    "    'project_grade_category'\n",
    "]\n",
    "print(u'开始编码')\n",
    "for i,col in enumerate(catagory_feature):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(combine_data[col].astype(str))\n",
    "    combine_data[col] = encoder.transform(combine_data[col].astype(str))\n",
    "    del encoder\n",
    "    gc.collect()\n",
    "print(u'完成编码')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 260115 entries, 0 to 260114\n",
      "Columns: 3147 entries, teacher_id to 38\n",
      "dtypes: float16(2817), int64(330)\n",
      "memory usage: 2.0 GB\n",
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Index' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-e335a23d7a84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mcombine_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat64_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombine_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat64_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcombine_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcombine_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'Index' object is not callable"
     ]
    }
   ],
   "source": [
    "drop_columns = [\n",
    "    'id',\n",
    "    'project_submitted_datetime',\n",
    "    'project_title',\n",
    "    'project_essay_1', \n",
    "    'project_essay_2',\n",
    "     'project_essay_3', \n",
    "    'project_essay_4', \n",
    "    'project_resource_summary',\n",
    "    'project_essay',\n",
    "    'project_subject_categories',\n",
    "    'project_subject_subcategories',\n",
    "    'resource_description'\n",
    "]\n",
    "\n",
    "combine_data = pd.concat([combine_data,cat_features],axis=1)\n",
    "combine_data = combine_data.drop(labels=drop_columns,axis=1,errors='ignore')\n",
    "float64_index = combine_data.select_dtypes(include=np.float64).columns\n",
    "combine_data[float64_index] = combine_data[float64_index].astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 260115 entries, 0 to 260114\n",
      "Columns: 3147 entries, teacher_id to 38\n",
      "dtypes: float16(2817), int64(330)\n",
      "memory usage: 2.0 GB\n",
      "None\n",
      "Index([                                  'teacher_id',\n",
      "                                     'teacher_prefix',\n",
      "                                       'school_state',\n",
      "                             'project_grade_category',\n",
      "       'teacher_number_of_previously_posted_projects',\n",
      "                                      'is_train_data',\n",
      "                                        'total_price',\n",
      "                                         'mean_price',\n",
      "                                     'quantity_count',\n",
      "                                       'quantity_sum',\n",
      "       ...\n",
      "                                                   29,\n",
      "                                                   30,\n",
      "                                                   31,\n",
      "                                                   32,\n",
      "                                                   33,\n",
      "                                                   34,\n",
      "                                                   35,\n",
      "                                                   36,\n",
      "                                                   37,\n",
      "                                                   38],\n",
      "      dtype='object', length=3147)\n"
     ]
    }
   ],
   "source": [
    "print (combine_data.info())\n",
    "print (combine_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28622"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = combine_data.loc[combine_data.is_train_data ==1,:].drop('is_train_data',axis=1,errors='ignore')\n",
    "test_X = combine_data.loc[combine_data.is_train_data != 1 ,:].drop('is_train_data',axis=1,errors='ignore')\n",
    "\n",
    "del train_data,test_data,resource,combine_data,cat_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.columns = train_X.columns.map(lambda x : str(x))\n",
    "test_X.columns = test_X.columns.map(lambda x : str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.776407\tvalid_1's auc: 0.757121\n",
      "[200]\ttraining's auc: 0.803814\tvalid_1's auc: 0.773438\n",
      "[300]\ttraining's auc: 0.821565\tvalid_1's auc: 0.780417\n",
      "[400]\ttraining's auc: 0.835224\tvalid_1's auc: 0.783873\n",
      "[500]\ttraining's auc: 0.846757\tvalid_1's auc: 0.785445\n",
      "[600]\ttraining's auc: 0.856928\tvalid_1's auc: 0.786604\n",
      "[700]\ttraining's auc: 0.866021\tvalid_1's auc: 0.787169\n",
      "[800]\ttraining's auc: 0.874449\tvalid_1's auc: 0.787097\n",
      "Early stopping, best iteration is:\n",
      "[747]\ttraining's auc: 0.869956\tvalid_1's auc: 0.787326\n",
      "Important features\n",
      "('project_essay_project_resource_summary_common', 388)\n",
      "('project_essay_resource_description_common', 341)\n",
      "('quantity_count', 266)\n",
      "('teacher_number_of_previously_posted_projects', 263)\n",
      "('project_essay2_word_len', 179)\n",
      "('project_resource_summary_word_len', 154)\n",
      "('project_essay_tfidf_1963', 143)\n",
      "('project_essay2_len', 138)\n",
      "('resource_description_-', 137)\n",
      "('project_essay_tfidf_1970', 133)\n",
      "('resource_description_len', 133)\n",
      "('project_essay_book', 128)\n",
      "('project_essay_tfidf_328', 124)\n",
      "('resource_description_word_len', 123)\n",
      "('project_essay_tfidf_1881', 120)\n",
      "('project_essay_tfidf_1697', 119)\n",
      "('total_price', 116)\n",
      "('project_essay_\\\\\\\\r', 112)\n",
      "('project_resource_summary_len', 105)\n",
      "('project_essay_tfidf_181', 101)\n",
      "('project_essay_tfidf_1720', 100)\n",
      "('project_essay_tfidf_1107', 99)\n",
      "('project_essay_tfidf_969', 91)\n",
      "('project_essay_tfidf_1882', 90)\n",
      "('project_essay_tfidf_835', 89)\n",
      "('project_essay_tfidf_298', 86)\n",
      "('month', 84)\n",
      "('project_essay_tfidf_1301', 81)\n",
      "('project_essay_tfidf_231', 81)\n",
      "('mean_price', 79)\n",
      "('project_resource_summary_tfidf_332', 74)\n",
      "('project_essay_tfidf_1104', 74)\n",
      "('project_essay_tfidf_1405', 73)\n",
      "('resource_description_\\\\.', 72)\n",
      "('project_essay_tfidf_1789', 71)\n",
      "('project_resource_summary_tfidf_19', 70)\n",
      "('project_essay_tfidf_85', 68)\n",
      "('quantity_sum', 68)\n",
      "('project_essay_tfidf_1323', 65)\n",
      "('project_essay_tfidf_1808', 64)\n",
      "('project_resource_summary_resource_description_common', 63)\n",
      "('project_essay_tfidf_1503', 62)\n",
      "('day', 62)\n",
      "('project_essay_tfidf_1747', 60)\n",
      "('project_essay_tfidf_1921', 59)\n",
      "('project_essay_tfidf_1511', 58)\n",
      "('project_essay_tfidf_1775', 57)\n",
      "('project_essay_tfidf_1539', 57)\n",
      "('project_essay_tfidf_1089', 57)\n",
      "('1', 56)\n",
      "('project_essay_tfidf_1750', 56)\n",
      "('project_essay_tfidf_1422', 56)\n",
      "('project_essay_tfidf_1766', 54)\n",
      "('project_essay3_len', 54)\n",
      "('project_essay_tfidf_1985', 52)\n",
      "('project_essay_tfidf_178', 52)\n",
      "('project_resource_summary_tfidf_220', 49)\n",
      "('project_essay_tfidf_1736', 49)\n",
      "('project_essay_tfidf_1234', 49)\n",
      "('project_essay_tfidf_1748', 48)\n",
      "0 AUC: 0.7873262728750493\n",
      "LGB_AUC = 0.787326 +/- 0.000000\n"
     ]
    }
   ],
   "source": [
    "#建立模型\n",
    "\n",
    "feature_names = list(train_X.columns)\n",
    "cnt = 0 \n",
    "p_buf = []\n",
    "n_splits = 5\n",
    "n_repeats = 1\n",
    "kf = RepeatedKFold(n_splits=n_splits,n_repeats=n_repeats,random_state=0)\n",
    "auc_buf=[]\n",
    "lgb_valid = []\n",
    "\n",
    "for train_index,valid_index in kf.split(train_X):\n",
    "    print('Fold {}/{}'.format(cnt+1,n_splits))\n",
    "#     lgb_params ={\n",
    "#         'boosting_type': 'gbdt',\n",
    "#         'objective':'binary',\n",
    "#         'metric':'auc',\n",
    "#         'max_depth':14,\n",
    "#         'num_leaves':31,\n",
    "#         'learning_rate':0.025,\n",
    "#         'feature_fraction':0.85,\n",
    "#         'bagging_fraction':0.85,\n",
    "#         'bagging_freq':5,\n",
    "#         'verbose':0,\n",
    "#         'lambda_l2':1.0,\n",
    "#         'num_threads': 1,\n",
    "#         'min_gain_to_split':0,\n",
    "#     }\n",
    "    lgb_params ={\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective':'binary',\n",
    "        'metric':'auc',\n",
    "        'max_depth':20,\n",
    "        'num_leaves':30,\n",
    "        'learning_rate':0.025,\n",
    "        'feature_fraction':0.7,\n",
    "        'bagging_fraction':0.7,\n",
    "        'bagging_freq':5,\n",
    "        'verbose':0,\n",
    "        'lambda_l2':0.001,\n",
    "        'num_threads': 1,\n",
    "        'min_gain_to_split':0,\n",
    "        'is_unbalance':True\n",
    "    }\n",
    "    lgb_train = lgb.Dataset(\n",
    "    train_X.loc[train_index],\n",
    "    train_y.loc[train_index],\n",
    "    feature_name=feature_names)\n",
    "    \n",
    "    lgb_train.raw_data = None\n",
    "    \n",
    "    lgb_valid = lgb.Dataset(\n",
    "    train_X.loc[valid_index],\n",
    "    train_y.loc[valid_index])\n",
    "    \n",
    "    lgb_valid.raw_data= None\n",
    "    \n",
    "    lgb_clf = lgb.train(\n",
    "    lgb_params,\n",
    "    lgb_train,\n",
    "    num_boost_round=10000,\n",
    "    valid_sets=[lgb_train,lgb_valid],\n",
    "    early_stopping_rounds=100,\n",
    "    verbose_eval=100\n",
    "    )\n",
    "    \n",
    "    if cnt==0:\n",
    "        importance = lgb_clf.feature_importance()\n",
    "        model_fnames = lgb_clf.feature_name()\n",
    "        tuples = sorted(zip(model_fnames, importance), key=lambda x: x[1])[::-1]\n",
    "        tuples = [x for x in tuples if x[1]>0]\n",
    "        print('Important features')\n",
    "        for i in range(60):\n",
    "            if i< len(tuples):\n",
    "                print(tuples[i])\n",
    "            else:\n",
    "                break\n",
    "        del importance,model_fnames,tuples\n",
    "        gc.collect()\n",
    "    \n",
    "    p = lgb_clf.predict(train_X.loc[valid_index],num_iteration = lgb_clf.best_iteration)\n",
    "    auc = roc_auc_score(train_y.loc[valid_index],p)\n",
    "    \n",
    "    print('{} AUC: {}'.format(cnt,auc))\n",
    "    \n",
    "    p = lgb_clf.predict(test_X,num_iteration = lgb_clf.best_iteration )\n",
    "    if len(p_buf) == 0:\n",
    "        p_buf = np.array(p,dtype=np.float16)\n",
    "    else:\n",
    "        p_buf += np.array(p, dtype=np.float16)\n",
    "    auc_buf.append(auc)\n",
    "        \n",
    "    del lgb_clf,lgb_train,lgb_valid,p\n",
    "    gc.collect()\n",
    "    cnt += 1\n",
    "    if cnt > 0:\n",
    "        break\n",
    "\n",
    "auc_mean = np.mean(auc_buf)\n",
    "auc_std = np.std(auc_buf)\n",
    "print('LGB_AUC = {:.6f} +/- {:.6f}'.format(auc_mean,auc_std))\n",
    "\n",
    "#preds = p_buf/cnt\n",
    "lgb_predicts = p_buf/cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
